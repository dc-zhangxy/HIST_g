{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型题：高频交易里，成交量预估是重要的一个环节。已知五分钟样例数据格式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Instrument</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230421</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>12.660000</td>\n",
       "      <td>4429000.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230421</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>000002.SZ</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>11810483.0</td>\n",
       "      <td>430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230421</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>000063.SZ</td>\n",
       "      <td>38.450001</td>\n",
       "      <td>25530656.0</td>\n",
       "      <td>730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230421</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>000069.SZ</td>\n",
       "      <td>5.090000</td>\n",
       "      <td>7344113.0</td>\n",
       "      <td>430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230421</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>000100.SZ</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>9927899.0</td>\n",
       "      <td>270000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Time Instrument      close      volume  industry\n",
       "0  20230421  09:35:00  000001.SZ  12.660000   4429000.0    480000\n",
       "1  20230421  09:35:00  000002.SZ  15.610000  11810483.0    430000\n",
       "2  20230421  09:35:00  000063.SZ  38.450001  25530656.0    730000\n",
       "3  20230421  09:35:00  000069.SZ   5.090000   7344113.0    430000\n",
       "4  20230421  09:35:00  000100.SZ   4.330000   9927899.0    270000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = pd.read_csv('task.csv')\n",
    "task.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 Date 是日期，Time 表示当前分钟末尾，即认为其中的 close 和 volume 是在 Time 那一\n",
    "瞬间可以获取到的。\n",
    "Close 表示 Time 时刻的价格，Volume 表示 Time 时刻结尾的前面五分钟\n",
    "成交量总和。\n",
    "Instrument 是个股标记，Industry 是某个行业标记，标记同类的股票可能会有\n",
    "一定关系。\n",
    "\n",
    "任务目标：预测未来五分钟的 volume，从 Time = 9:40:00 开始预测（你可以用当天第一个\n",
    "bar 的数据了）\n",
    "\n",
    "任务提示：\n",
    "\n",
    "1、不能隐含使用未来数据（如 pandas 直接 sum all 把未来数据加起来了）\n",
    "\n",
    "2、每个股票 volume 都不一样，而且漂移严重，你需要找合适的替代指标来做模型（比如 current\n",
    "vol / history n bar volume sum）。\n",
    "\n",
    "3、你的 benchmark 就是过去一段时间的均值。\n",
    "\n",
    "4、或许同行业数据可以使用到个票预测上。\n",
    "\n",
    "任务要求：代码需要有一定结构，包括数据预处理、简单因子/特征的构建、模型 train、valid、\n",
    "test 划分、最终对比评价。Train 用来训练、valid 验证/早停、test 是模型外验证。根据不同\n",
    "模型构建评价指标。灵活处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrument</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">000001.SZ</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>12.66</td>\n",
       "      <td>4429000.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:40:00</th>\n",
       "      <td>12.67</td>\n",
       "      <td>2707900.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:45:00</th>\n",
       "      <td>12.71</td>\n",
       "      <td>1866802.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:50:00</th>\n",
       "      <td>12.76</td>\n",
       "      <td>2235400.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:55:00</th>\n",
       "      <td>12.79</td>\n",
       "      <td>4146100.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close     volume  industry\n",
       "Instrument Date     Time                                \n",
       "000001.SZ  20230421 09:35:00  12.66  4429000.0    480000\n",
       "                    09:40:00  12.67  2707900.0    480000\n",
       "                    09:45:00  12.71  1866802.0    480000\n",
       "                    09:50:00  12.76  2235400.0    480000\n",
       "                    09:55:00  12.79  4146100.0    480000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = task.copy()\n",
    "df_mul = data.set_index(['Instrument', 'Date','Time'], drop=True)\n",
    "data = df_mul.sort_index(level='Instrument')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单因子特征的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取时间相关特征\n",
    "data['Hour'] = np.array(pd.to_datetime(data.reset_index()['Time']).dt.hour)\n",
    "data['Minute'] = np.array(pd.to_datetime(data.reset_index()['Time']).dt.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算行业平均成交量\n",
    "industry_avg_volume = data.groupby(['industry', 'Date', 'Time'])['volume'].mean().reset_index()\n",
    "industry_avg_volume.rename(columns={'volume': 'IndustryAvgVolume'}, inplace=True)\n",
    "# 使用 join 方法将计算出的平均成交量数据合并到原始的 DataFrame 中\n",
    "data = data.join(industry_avg_volume.set_index(['industry','Date', 'Time']), on=['industry','Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算行业成交量波动\n",
    "industry_std_volume = data.groupby(['industry', 'Date', 'Time'])['volume'].std().reset_index()\n",
    "industry_std_volume.rename(columns={'volume': 'IndustryStdVolume'}, inplace=True)\n",
    "# 使用 join 方法将计算出的平均成交量数据合并到原始的 DataFrame 中\n",
    "data = data.join(industry_std_volume.set_index(['industry','Date', 'Time']), on=['industry','Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算行业均价\n",
    "industry_avg_close = data.groupby(['industry', 'Date', 'Time'])['close'].mean().reset_index()\n",
    "industry_avg_close.rename(columns={'close': 'IndustryAvgClose'}, inplace=True)\n",
    "data = data.join(industry_avg_close.set_index(['industry','Date', 'Time']), on=['industry','Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算行业波动率\n",
    "industry_volatility = data.groupby(['industry', 'Date', 'Time'])['close'].std().reset_index()\n",
    "industry_volatility.rename(columns={'close': 'IndustryVolatility'}, inplace=True)\n",
    "data = data.join(industry_volatility.set_index(['industry','Date', 'Time']), on=['industry','Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成过去30天的时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/354423847.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n"
     ]
    }
   ],
   "source": [
    "# 生成新的列\n",
    "for i in range(29-1,-1,-1):\n",
    "    data[f'past_close_{i+1}'] = data.groupby('Instrument')['close'].shift(i+1)/data['close']\n",
    "    data[f'past_volume_{i+1}'] = data.groupby('Instrument')['volume'].shift(i+1)/data['volume']\n",
    "    data[f'past_Hour_{i+1}'] = data.groupby('Instrument')['Hour'].shift(i+1)\n",
    "    data[f'past_Minute_{i+1}'] = data.groupby('Instrument')['Minute'].shift(i+1)\n",
    "    data[f'past_IAV_{i+1}'] = data.groupby('Instrument')['IndustryAvgVolume'].shift(i+1)/data['volume']\n",
    "    data[f'past_ISV_{i+1}'] = data.groupby('Instrument')['IndustryStdVolume'].shift(i+1)/data['volume']\n",
    "    data[f'past_IAC_{i+1}'] = data.groupby('Instrument')['IndustryAvgClose'].shift(i+1)/data['close']\n",
    "    data[f'past_ISC_{i+1}'] = data.groupby('Instrument')['IndustryVolatility'].shift(i+1)/data['close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/3223193793.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'volume_{1}'] = data.groupby('Instrument')['volume'].shift(-1)\n",
      "/home/xiaoguang/xinyi/qxquant/ipykernel_8183/3223193793.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['volume_label1'] = data[f'volume_{1}']/data['volume']\n"
     ]
    }
   ],
   "source": [
    "# 生成label\n",
    "data[f'volume_{1}'] = data.groupby('Instrument')['volume'].shift(-1)\n",
    "data['volume_label1'] = data[f'volume_{1}']/data['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>industry</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>IndustryAvgVolume</th>\n",
       "      <th>IndustryStdVolume</th>\n",
       "      <th>IndustryAvgClose</th>\n",
       "      <th>IndustryVolatility</th>\n",
       "      <th>past_close_29</th>\n",
       "      <th>...</th>\n",
       "      <th>past_close_1</th>\n",
       "      <th>past_volume_1</th>\n",
       "      <th>past_Hour_1</th>\n",
       "      <th>past_Minute_1</th>\n",
       "      <th>past_IAV_1</th>\n",
       "      <th>past_ISV_1</th>\n",
       "      <th>past_IAC_1</th>\n",
       "      <th>past_ISC_1</th>\n",
       "      <th>volume_1</th>\n",
       "      <th>volume_label1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrument</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">000001.SZ</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20230421</th>\n",
       "      <th>13:30:00</th>\n",
       "      <td>12.61</td>\n",
       "      <td>1065100.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>1.191376e+06</td>\n",
       "      <td>1.011870e+06</td>\n",
       "      <td>9.558095</td>\n",
       "      <td>8.156538</td>\n",
       "      <td>1.003965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000793</td>\n",
       "      <td>1.137734</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.353180</td>\n",
       "      <td>1.399048</td>\n",
       "      <td>0.757902</td>\n",
       "      <td>0.647030</td>\n",
       "      <td>1953600.0</td>\n",
       "      <td>1.834194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:35:00</th>\n",
       "      <td>12.59</td>\n",
       "      <td>1953600.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>1.584959e+06</td>\n",
       "      <td>1.605637e+06</td>\n",
       "      <td>9.539524</td>\n",
       "      <td>8.134215</td>\n",
       "      <td>1.006354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001589</td>\n",
       "      <td>0.545199</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.517952</td>\n",
       "      <td>0.759181</td>\n",
       "      <td>0.647858</td>\n",
       "      <td>1634972.0</td>\n",
       "      <td>0.836902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:40:00</th>\n",
       "      <td>12.59</td>\n",
       "      <td>1634972.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>1.984549e+06</td>\n",
       "      <td>1.994986e+06</td>\n",
       "      <td>9.536667</td>\n",
       "      <td>8.134369</td>\n",
       "      <td>1.009531</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.194883</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.969410</td>\n",
       "      <td>0.982058</td>\n",
       "      <td>0.757706</td>\n",
       "      <td>0.646085</td>\n",
       "      <td>1555236.0</td>\n",
       "      <td>0.951231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:45:00</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1555236.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>2.306005e+06</td>\n",
       "      <td>2.240732e+06</td>\n",
       "      <td>9.520476</td>\n",
       "      <td>8.109616</td>\n",
       "      <td>1.014308</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000795</td>\n",
       "      <td>1.051269</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.282754</td>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.646611</td>\n",
       "      <td>1044700.0</td>\n",
       "      <td>0.671731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13:50:00</th>\n",
       "      <td>12.60</td>\n",
       "      <td>1044700.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>1.443919e+06</td>\n",
       "      <td>1.454847e+06</td>\n",
       "      <td>9.525238</td>\n",
       "      <td>8.128511</td>\n",
       "      <td>1.015079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>1.488691</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.207337</td>\n",
       "      <td>2.144857</td>\n",
       "      <td>0.755593</td>\n",
       "      <td>0.643620</td>\n",
       "      <td>742200.0</td>\n",
       "      <td>0.710443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close     volume  industry  Hour  Minute  \\\n",
       "Instrument Date     Time                                                 \n",
       "000001.SZ  20230421 13:30:00  12.61  1065100.0    480000    13      30   \n",
       "                    13:35:00  12.59  1953600.0    480000    13      35   \n",
       "                    13:40:00  12.59  1634972.0    480000    13      40   \n",
       "                    13:45:00  12.58  1555236.0    480000    13      45   \n",
       "                    13:50:00  12.60  1044700.0    480000    13      50   \n",
       "\n",
       "                              IndustryAvgVolume  IndustryStdVolume  \\\n",
       "Instrument Date     Time                                             \n",
       "000001.SZ  20230421 13:30:00       1.191376e+06       1.011870e+06   \n",
       "                    13:35:00       1.584959e+06       1.605637e+06   \n",
       "                    13:40:00       1.984549e+06       1.994986e+06   \n",
       "                    13:45:00       2.306005e+06       2.240732e+06   \n",
       "                    13:50:00       1.443919e+06       1.454847e+06   \n",
       "\n",
       "                              IndustryAvgClose  IndustryVolatility  \\\n",
       "Instrument Date     Time                                             \n",
       "000001.SZ  20230421 13:30:00          9.558095            8.156538   \n",
       "                    13:35:00          9.539524            8.134215   \n",
       "                    13:40:00          9.536667            8.134369   \n",
       "                    13:45:00          9.520476            8.109616   \n",
       "                    13:50:00          9.525238            8.128511   \n",
       "\n",
       "                              past_close_29  ...  past_close_1  past_volume_1  \\\n",
       "Instrument Date     Time                     ...                                \n",
       "000001.SZ  20230421 13:30:00       1.003965  ...      1.000793       1.137734   \n",
       "                    13:35:00       1.006354  ...      1.001589       0.545199   \n",
       "                    13:40:00       1.009531  ...      1.000000       1.194883   \n",
       "                    13:45:00       1.014308  ...      1.000795       1.051269   \n",
       "                    13:50:00       1.015079  ...      0.998413       1.488691   \n",
       "\n",
       "                              past_Hour_1  past_Minute_1  past_IAV_1  \\\n",
       "Instrument Date     Time                                               \n",
       "000001.SZ  20230421 13:30:00         13.0           25.0    1.353180   \n",
       "                    13:35:00         13.0           30.0    0.609836   \n",
       "                    13:40:00         13.0           35.0    0.969410   \n",
       "                    13:45:00         13.0           40.0    1.276043   \n",
       "                    13:50:00         13.0           45.0    2.207337   \n",
       "\n",
       "                              past_ISV_1  past_IAC_1  past_ISC_1   volume_1  \\\n",
       "Instrument Date     Time                                                      \n",
       "000001.SZ  20230421 13:30:00    1.399048    0.757902    0.647030  1953600.0   \n",
       "                    13:35:00    0.517952    0.759181    0.647858  1634972.0   \n",
       "                    13:40:00    0.982058    0.757706    0.646085  1555236.0   \n",
       "                    13:45:00    1.282754    0.758082    0.646611  1044700.0   \n",
       "                    13:50:00    2.144857    0.755593    0.643620   742200.0   \n",
       "\n",
       "                              volume_label1  \n",
       "Instrument Date     Time                     \n",
       "000001.SZ  20230421 13:30:00       1.834194  \n",
       "                    13:35:00       0.836902  \n",
       "                    13:40:00       0.951231  \n",
       "                    13:45:00       0.671731  \n",
       "                    13:50:00       0.710443  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化原始数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['IndustryAvgVolume'] = data['IndustryAvgVolume']/data['volume']\n",
    "data['IndustryStdVolume'] = data['IndustryStdVolume']/data['volume']\n",
    "data['IndustryAvgClose'] = data['IndustryAvgClose'] /data['close']\n",
    "data['IndustryVolatility'] = data['IndustryVolatility']/data['close']\n",
    "# data['volume'] = 1.\n",
    "# data['close'] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna().reset_index().drop('industry', axis=1).to_feather('task_8_30_IDT.feather') #.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_new = feather.read_dataframe('task_8_30_IDT.feather')\n",
    "# df_train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrument</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001.SZ</th>\n",
       "      <th>20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>12.660000</td>\n",
       "      <td>4429000.0</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.SZ</th>\n",
       "      <th>20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>15.610000</td>\n",
       "      <td>11810483.0</td>\n",
       "      <td>430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000063.SZ</th>\n",
       "      <th>20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>38.450001</td>\n",
       "      <td>25530656.0</td>\n",
       "      <td>730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000069.SZ</th>\n",
       "      <th>20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>5.090000</td>\n",
       "      <td>7344113.0</td>\n",
       "      <td>430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000100.SZ</th>\n",
       "      <th>20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>4.330000</td>\n",
       "      <td>9927899.0</td>\n",
       "      <td>270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688363.SH</th>\n",
       "      <th>20230803</th>\n",
       "      <th>15:00:00</th>\n",
       "      <td>95.790001</td>\n",
       "      <td>39556.0</td>\n",
       "      <td>770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688396.SH</th>\n",
       "      <th>20230803</th>\n",
       "      <th>15:00:00</th>\n",
       "      <td>55.720001</td>\n",
       "      <td>65426.0</td>\n",
       "      <td>270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688561.SH</th>\n",
       "      <th>20230803</th>\n",
       "      <th>15:00:00</th>\n",
       "      <td>51.070000</td>\n",
       "      <td>31368.0</td>\n",
       "      <td>710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688599.SH</th>\n",
       "      <th>20230803</th>\n",
       "      <th>15:00:00</th>\n",
       "      <td>37.259998</td>\n",
       "      <td>123220.0</td>\n",
       "      <td>630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688981.SH</th>\n",
       "      <th>20230803</th>\n",
       "      <th>15:00:00</th>\n",
       "      <td>50.910000</td>\n",
       "      <td>196869.0</td>\n",
       "      <td>270000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  close      volume  industry\n",
       "Instrument Date     Time                                     \n",
       "000001.SZ  20230421 09:35:00  12.660000   4429000.0    480000\n",
       "000002.SZ  20230421 09:35:00  15.610000  11810483.0    430000\n",
       "000063.SZ  20230421 09:35:00  38.450001  25530656.0    730000\n",
       "000069.SZ  20230421 09:35:00   5.090000   7344113.0    430000\n",
       "000100.SZ  20230421 09:35:00   4.330000   9927899.0    270000\n",
       "...                                 ...         ...       ...\n",
       "688363.SH  20230803 15:00:00  95.790001     39556.0    770000\n",
       "688396.SH  20230803 15:00:00  55.720001     65426.0    270000\n",
       "688561.SH  20230803 15:00:00  51.070000     31368.0    710000\n",
       "688599.SH  20230803 15:00:00  37.259998    123220.0    630000\n",
       "688981.SH  20230803 15:00:00  50.910000    196869.0    270000\n",
       "\n",
       "[1008000 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_new = feather.read_dataframe('task_30.feather')\n",
    "df_train_new = task.copy()\n",
    "\n",
    "df_mul = df_train_new.set_index(['Instrument', 'Date','Time'], drop=True)\n",
    "df_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = df_train_new['Date'].drop_duplicates().to_list() # 70天\n",
    "total_time_len = len(total_time)\n",
    "\n",
    "train_end_index = int(total_time_len*0.8) # 56 #\n",
    "valid_end_index = int(total_time_len*0.9) # 63 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20230421, 20230717, 20230726, 20230803)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time[0],total_time[train_end_index],total_time[valid_end_index],total_time[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mul = data.set_index(['Instrument', 'Date','Time'], drop=True)\n",
    "data = df_mul.sort_index(level='Instrument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用过去30天均值预测\n",
    "data['rolling_volume30_mean']= np.array(data.groupby('Instrument')['volume'].rolling(30).mean())\n",
    "data['volume30_predict'] = data['rolling_volume30_mean']/data['volume']\n",
    "# 生成label\n",
    "data[f'volume_{1}'] = data.groupby('Instrument')['volume'].shift(-1)\n",
    "data['volume_label1'] = data[f'volume_{1}']/data['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>industry</th>\n",
       "      <th>rolling_volume30_mean</th>\n",
       "      <th>volume30_predict</th>\n",
       "      <th>volume_1</th>\n",
       "      <th>volume_label1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrument</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">000001.SZ</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20230421</th>\n",
       "      <th>09:35:00</th>\n",
       "      <td>12.660000</td>\n",
       "      <td>4429000.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2707900.0</td>\n",
       "      <td>0.611402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:40:00</th>\n",
       "      <td>12.670000</td>\n",
       "      <td>2707900.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1866802.0</td>\n",
       "      <td>0.689391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:45:00</th>\n",
       "      <td>12.710000</td>\n",
       "      <td>1866802.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2235400.0</td>\n",
       "      <td>1.197449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:50:00</th>\n",
       "      <td>12.760000</td>\n",
       "      <td>2235400.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4146100.0</td>\n",
       "      <td>1.854746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:55:00</th>\n",
       "      <td>12.790000</td>\n",
       "      <td>4146100.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3209570.0</td>\n",
       "      <td>0.774118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">688981.SH</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20230803</th>\n",
       "      <th>14:40:00</th>\n",
       "      <td>50.990002</td>\n",
       "      <td>250869.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>190005.700000</td>\n",
       "      <td>0.757390</td>\n",
       "      <td>211027.0</td>\n",
       "      <td>0.841184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:45:00</th>\n",
       "      <td>50.910000</td>\n",
       "      <td>211027.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>193382.933333</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>306030.0</td>\n",
       "      <td>1.450194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:50:00</th>\n",
       "      <td>50.990002</td>\n",
       "      <td>306030.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>198559.333333</td>\n",
       "      <td>0.648823</td>\n",
       "      <td>295822.0</td>\n",
       "      <td>0.966644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:55:00</th>\n",
       "      <td>50.950001</td>\n",
       "      <td>295822.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>203113.666667</td>\n",
       "      <td>0.686608</td>\n",
       "      <td>196869.0</td>\n",
       "      <td>0.665498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00:00</th>\n",
       "      <td>50.910000</td>\n",
       "      <td>196869.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>204770.166667</td>\n",
       "      <td>1.040134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  close     volume  industry  \\\n",
       "Instrument Date     Time                                       \n",
       "000001.SZ  20230421 09:35:00  12.660000  4429000.0    480000   \n",
       "                    09:40:00  12.670000  2707900.0    480000   \n",
       "                    09:45:00  12.710000  1866802.0    480000   \n",
       "                    09:50:00  12.760000  2235400.0    480000   \n",
       "                    09:55:00  12.790000  4146100.0    480000   \n",
       "...                                 ...        ...       ...   \n",
       "688981.SH  20230803 14:40:00  50.990002   250869.0    270000   \n",
       "                    14:45:00  50.910000   211027.0    270000   \n",
       "                    14:50:00  50.990002   306030.0    270000   \n",
       "                    14:55:00  50.950001   295822.0    270000   \n",
       "                    15:00:00  50.910000   196869.0    270000   \n",
       "\n",
       "                              rolling_volume30_mean  volume30_predict  \\\n",
       "Instrument Date     Time                                                \n",
       "000001.SZ  20230421 09:35:00                    NaN               NaN   \n",
       "                    09:40:00                    NaN               NaN   \n",
       "                    09:45:00                    NaN               NaN   \n",
       "                    09:50:00                    NaN               NaN   \n",
       "                    09:55:00                    NaN               NaN   \n",
       "...                                             ...               ...   \n",
       "688981.SH  20230803 14:40:00          190005.700000          0.757390   \n",
       "                    14:45:00          193382.933333          0.916390   \n",
       "                    14:50:00          198559.333333          0.648823   \n",
       "                    14:55:00          203113.666667          0.686608   \n",
       "                    15:00:00          204770.166667          1.040134   \n",
       "\n",
       "                               volume_1  volume_label1  \n",
       "Instrument Date     Time                                \n",
       "000001.SZ  20230421 09:35:00  2707900.0       0.611402  \n",
       "                    09:40:00  1866802.0       0.689391  \n",
       "                    09:45:00  2235400.0       1.197449  \n",
       "                    09:50:00  4146100.0       1.854746  \n",
       "                    09:55:00  3209570.0       0.774118  \n",
       "...                                 ...            ...  \n",
       "688981.SH  20230803 14:40:00   211027.0       0.841184  \n",
       "                    14:45:00   306030.0       1.450194  \n",
       "                    14:50:00   295822.0       0.966644  \n",
       "                    14:55:00   196869.0       0.665498  \n",
       "                    15:00:00        NaN            NaN  \n",
       "\n",
       "[1008000 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadrop = data.dropna().reset_index().set_index([ 'Date','Time', 'Instrument'], drop=True)\n",
    "# datadrop = datadrop.sort_index(level=['Date','Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = datadrop.loc[total_time[valid_end_index:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>industry</th>\n",
       "      <th>rolling_volume30_mean</th>\n",
       "      <th>volume30_predict</th>\n",
       "      <th>volume_1</th>\n",
       "      <th>volume_label1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Instrument</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20230726</th>\n",
       "      <th>09:35:00</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>11.690000</td>\n",
       "      <td>6364800.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>3.024844e+06</td>\n",
       "      <td>0.475246</td>\n",
       "      <td>4063180.0</td>\n",
       "      <td>0.638383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:40:00</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>11.720000</td>\n",
       "      <td>4063180.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>3.062547e+06</td>\n",
       "      <td>0.753732</td>\n",
       "      <td>3260720.0</td>\n",
       "      <td>0.802504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:45:00</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>11.660000</td>\n",
       "      <td>3260720.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>3.151011e+06</td>\n",
       "      <td>0.966354</td>\n",
       "      <td>2042600.0</td>\n",
       "      <td>0.626426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:50:00</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>11.670000</td>\n",
       "      <td>2042600.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>3.161531e+06</td>\n",
       "      <td>1.547797</td>\n",
       "      <td>3007900.0</td>\n",
       "      <td>1.472584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09:55:00</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>11.660000</td>\n",
       "      <td>3007900.0</td>\n",
       "      <td>480000</td>\n",
       "      <td>3.196261e+06</td>\n",
       "      <td>1.062622</td>\n",
       "      <td>1525300.0</td>\n",
       "      <td>0.507098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20230803</th>\n",
       "      <th>14:35:00</th>\n",
       "      <th>688981.SH</th>\n",
       "      <td>50.990002</td>\n",
       "      <td>194935.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>1.859326e+05</td>\n",
       "      <td>0.953818</td>\n",
       "      <td>250869.0</td>\n",
       "      <td>1.286937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:40:00</th>\n",
       "      <th>688981.SH</th>\n",
       "      <td>50.990002</td>\n",
       "      <td>250869.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>1.900057e+05</td>\n",
       "      <td>0.757390</td>\n",
       "      <td>211027.0</td>\n",
       "      <td>0.841184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:45:00</th>\n",
       "      <th>688981.SH</th>\n",
       "      <td>50.910000</td>\n",
       "      <td>211027.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>1.933829e+05</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>306030.0</td>\n",
       "      <td>1.450194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:50:00</th>\n",
       "      <th>688981.SH</th>\n",
       "      <td>50.990002</td>\n",
       "      <td>306030.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>1.985593e+05</td>\n",
       "      <td>0.648823</td>\n",
       "      <td>295822.0</td>\n",
       "      <td>0.966644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14:55:00</th>\n",
       "      <th>688981.SH</th>\n",
       "      <td>50.950001</td>\n",
       "      <td>295822.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>2.031137e+05</td>\n",
       "      <td>0.686608</td>\n",
       "      <td>196869.0</td>\n",
       "      <td>0.665498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  close     volume  industry  \\\n",
       "Date     Time     Instrument                                   \n",
       "20230726 09:35:00 000001.SZ   11.690000  6364800.0    480000   \n",
       "         09:40:00 000001.SZ   11.720000  4063180.0    480000   \n",
       "         09:45:00 000001.SZ   11.660000  3260720.0    480000   \n",
       "         09:50:00 000001.SZ   11.670000  2042600.0    480000   \n",
       "         09:55:00 000001.SZ   11.660000  3007900.0    480000   \n",
       "...                                 ...        ...       ...   \n",
       "20230803 14:35:00 688981.SH   50.990002   194935.0    270000   \n",
       "         14:40:00 688981.SH   50.990002   250869.0    270000   \n",
       "         14:45:00 688981.SH   50.910000   211027.0    270000   \n",
       "         14:50:00 688981.SH   50.990002   306030.0    270000   \n",
       "         14:55:00 688981.SH   50.950001   295822.0    270000   \n",
       "\n",
       "                              rolling_volume30_mean  volume30_predict  \\\n",
       "Date     Time     Instrument                                            \n",
       "20230726 09:35:00 000001.SZ            3.024844e+06          0.475246   \n",
       "         09:40:00 000001.SZ            3.062547e+06          0.753732   \n",
       "         09:45:00 000001.SZ            3.151011e+06          0.966354   \n",
       "         09:50:00 000001.SZ            3.161531e+06          1.547797   \n",
       "         09:55:00 000001.SZ            3.196261e+06          1.062622   \n",
       "...                                             ...               ...   \n",
       "20230803 14:35:00 688981.SH            1.859326e+05          0.953818   \n",
       "         14:40:00 688981.SH            1.900057e+05          0.757390   \n",
       "         14:45:00 688981.SH            1.933829e+05          0.916390   \n",
       "         14:50:00 688981.SH            1.985593e+05          0.648823   \n",
       "         14:55:00 688981.SH            2.031137e+05          0.686608   \n",
       "\n",
       "                               volume_1  volume_label1  \n",
       "Date     Time     Instrument                            \n",
       "20230726 09:35:00 000001.SZ   4063180.0       0.638383  \n",
       "         09:40:00 000001.SZ   3260720.0       0.802504  \n",
       "         09:45:00 000001.SZ   2042600.0       0.626426  \n",
       "         09:50:00 000001.SZ   3007900.0       1.472584  \n",
       "         09:55:00 000001.SZ   1525300.0       0.507098  \n",
       "...                                 ...            ...  \n",
       "20230803 14:35:00 688981.SH    250869.0       1.286937  \n",
       "         14:40:00 688981.SH    211027.0       0.841184  \n",
       "         14:45:00 688981.SH    306030.0       1.450194  \n",
       "         14:50:00 688981.SH    295822.0       0.966644  \n",
       "         14:55:00 688981.SH    196869.0       0.665498  \n",
       "\n",
       "[100500 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataCSnorm = datadrop.groupby(level=['Date','Time'],group_keys=False).apply(lambda x:(x-x.mean() )/x.std() )\n",
    "# dataCSnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanorm = df_test.apply(lambda x:(x-x.mean() )/x.std() )   # (df-df.mean())/df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4228578895900704"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanorm.groupby(level=['Date','Time']).apply(lambda x: np.mean(x['volume30_predict']-x['volume_label1'])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4694772821724271"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanorm.groupby(level=['Date','Time']).apply(lambda x: x['volume30_predict'].corr(x['volume_label1'], method='spearman')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40639092862444837"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanorm.groupby(level=['Date','Time']).apply(lambda x: x['volume30_predict'].corr(x['volume_label1'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU训练结果计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred5=pickle.load(open('output/all_GRU_feat8_new/pred.pkl.test0','rb'))\n",
    "# test_pred5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47352213433465157"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_norm = test_pred5.apply(lambda x:(x-x.mean() )/x.std() )\n",
    "test_pred5.groupby(level=['Date','Time']).apply(lambda x: x['score'].corr(x['label'], method='spearman')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41797989090879084"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred5.groupby(level=['Date','Time']).apply(lambda x: x['score'].corr(x['label'])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02216416806877501"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred5.groupby(level=['Date','Time']).apply(lambda x: np.mean(x['score']-x['label'])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
